{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##1. Загрузка пакетов - библиотек"
      ],
      "metadata": {
        "id": "irNrFiBZHxDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импорт необходимых библиотек\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import shutil\n",
        "import random\n",
        "from keras import models, layers\n",
        "from keras import regularizers\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Установка seed для воспроизводимости результатов\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "m9HnSAoNKXqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Загрузка датасета"
      ],
      "metadata": {
        "id": "B4VoSphR0f2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_root = Path(\"/content/iad-lab3/Vehicles\")\n",
        "\n",
        "# Проверка наличия датасета\n",
        "if dataset_root.exists():\n",
        "    print(\"Датасет уже найден по указанному пути.\")\n",
        "else:\n",
        "    print(\"Датасет не найден. Выполняется загрузка с GitHub...\")\n",
        "    !git clone https://github.com/Daria-Chernykh/iad-lab3.git\n",
        "\n",
        "# Получение списка классов (подкаталогов)\n",
        "class_names = sorted(\n",
        "    [item.name for item in dataset_root.iterdir() if item.is_dir()]\n",
        ")\n",
        "\n",
        "# Фиксация количества классов\n",
        "num_classes = len(class_names)\n",
        "\n",
        "print(\"\\nНайденные классы:\")\n",
        "for idx, class_name in enumerate(class_names):\n",
        "    print(f\"{idx + 1}. {class_name}\")\n",
        "\n",
        "print(f\"\\nКоличество классов k = {num_classes}\")\n",
        "\n",
        "# Допустимые расширения изображений (в нижнем регистре)\n",
        "image_extensions = {\".jpg\", \".jpeg\", \".png\", \".gif\", \".webp\"}\n",
        "\n",
        "# Подсчёт количества изображений в каждой папке класса\n",
        "print(\"\\nКоличество изображений по классам:\")\n",
        "\n",
        "total_images = 0\n",
        "\n",
        "for class_name in class_names:\n",
        "    class_path = dataset_root / class_name\n",
        "\n",
        "    num_images = sum(\n",
        "        1 for f in class_path.iterdir()\n",
        "        if f.is_file() and f.suffix.lower() in image_extensions\n",
        "    )\n",
        "\n",
        "    total_images += num_images\n",
        "    print(f\"{class_name}: {num_images}\")\n",
        "\n",
        "print(f\"\\nОбщее количество изображений в датасете: {total_images}\")"
      ],
      "metadata": {
        "id": "iOSiIIAa2LE9",
        "outputId": "6e18a5b6-e6bf-47c2-e32d-8c8f5b53b160",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Датасет уже найден по указанному пути.\n",
            "\n",
            "Найденные классы:\n",
            "1. Auto Rickshaws\n",
            "2. Bikes\n",
            "3. Cars\n",
            "4. Motorcycles\n",
            "5. Planes\n",
            "6. Ships\n",
            "7. Trains\n",
            "\n",
            "Количество классов k = 7\n",
            "\n",
            "Количество изображений по классам:\n",
            "Auto Rickshaws: 800\n",
            "Bikes: 800\n",
            "Cars: 790\n",
            "Motorcycles: 800\n",
            "Planes: 800\n",
            "Ships: 800\n",
            "Trains: 800\n",
            "\n",
            "Общее количество изображений в датасете: 5590\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В лабораторной работе используется датасет изображений транспортных средств (Vehicles). Набор данных включает 7 классов:\n",
        "* Авторикши (Auto Rickshaws),\n",
        "* Велосипеды (Bikes),\n",
        "* Машины (Cars),\n",
        "* Мотоциклы (Motorcycles),\n",
        "* Самолеты (Planes),\n",
        "* Корабли (Ships),\n",
        "* Поезда (Trains).\n",
        "\n",
        "Каждый класс представлен отдельной папкой с изображениями. Общее количество изображений в датасете составляет 5590. Число изображений в классах близко по величине (от 790 до 800 изображений на класс), что позволяет считать датасет практически сбалансированным и пригодным для решения задачи многоклассовой классификации с использованием сверточных нейронных сетей."
      ],
      "metadata": {
        "id": "RLYGz73vqKMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Выбор и фиксация размерности изображений"
      ],
      "metadata": {
        "id": "hpBia6nQutTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Фиксация размерности входных изображений\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "input_shape = (img_height, img_width, 3)\n",
        "\n",
        "# Размер мини-пакета\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "XNlRPlVYu1cJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Формирование обучающей, валидационной и тестовой выборок"
      ],
      "metadata": {
        "id": "rQj-wGD0wmsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####4.1 Физическое разбиение датасета по папкам"
      ],
      "metadata": {
        "id": "5XvMBL3w2rpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_root = Path(\"/content/iad-lab3/Vehicles\")\n",
        "target_root = Path(\"/content/Vehicles_split\")\n",
        "\n",
        "train_ratio = 0.6\n",
        "val_ratio = 0.2\n",
        "test_ratio = 0.2\n",
        "\n",
        "image_extensions = {\".jpg\", \".jpeg\", \".png\", \".gif\", \".webp\"}\n",
        "\n",
        "# Создание структуры каталогов\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    for class_dir in source_root.iterdir():\n",
        "        if class_dir.is_dir():\n",
        "            (target_root / split / class_dir.name).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Разбиение изображений по классам\n",
        "for class_dir in source_root.iterdir():\n",
        "    if not class_dir.is_dir():\n",
        "        continue\n",
        "\n",
        "    images = [\n",
        "        img for img in class_dir.iterdir()\n",
        "        if img.is_file() and img.suffix.lower() in image_extensions\n",
        "    ]\n",
        "\n",
        "    random.shuffle(images)\n",
        "\n",
        "    n_total = len(images)\n",
        "    n_train = int(n_total * train_ratio)\n",
        "    n_val = int(n_total * val_ratio)\n",
        "\n",
        "    train_images = images[:n_train]\n",
        "    val_images = images[n_train:n_train + n_val]\n",
        "    test_images = images[n_train + n_val:]\n",
        "\n",
        "    for img in train_images:\n",
        "        shutil.copy(img, target_root / \"train\" / class_dir.name / img.name)\n",
        "\n",
        "    for img in val_images:\n",
        "        shutil.copy(img, target_root / \"val\" / class_dir.name / img.name)\n",
        "\n",
        "    for img in test_images:\n",
        "        shutil.copy(img, target_root / \"test\" / class_dir.name / img.name)\n",
        "\n",
        "print(\"Разбиение датасета на train / val / test завершено.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMu-ECS12wS6",
        "outputId": "a235635f-f650-415a-9df9-8a8f8436e8f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Разбиение датасета на train / val / test завершено.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####4.2 Создание генераторов изображений"
      ],
      "metadata": {
        "id": "NF2Xf7XZ3BKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Генератор с аугментацией — только для обучающей выборки\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Генераторы без аугментации — для валидации и теста\n",
        "val_test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    target_root / \"train\",\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "val_generator = val_test_datagen.flow_from_directory(\n",
        "    target_root / \"val\",\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    target_root / \"test\",\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFzH1bZ-wxWB",
        "outputId": "7eac7cb3-aac5-4c2e-e61f-62410b329eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3352 images belonging to 7 classes.\n",
            "Found 1117 images belonging to 7 classes.\n",
            "Found 1118 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####4.3 Вывод количества изображений в каждой выборке"
      ],
      "metadata": {
        "id": "fCVokdIs3K0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_train = train_generator.samples\n",
        "num_val = val_generator.samples\n",
        "num_test = test_generator.samples\n",
        "\n",
        "print(\"Количество изображений в выборках:\")\n",
        "print(f\"Обучающая выборка: {num_train}\")\n",
        "print(f\"Валидационная выборка: {num_val}\")\n",
        "print(f\"Тестовая выборка: {num_test}\")\n",
        "print(f\"Общее количество изображений: {num_train + num_val + num_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3VsfvFF3OxT",
        "outputId": "fefe2aa0-f40f-4fb9-f0e6-0292b139e1ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество изображений в выборках:\n",
            "Обучающая выборка: 3352\n",
            "Валидационная выборка: 1117\n",
            "Тестовая выборка: 1118\n",
            "Общее количество изображений: 5587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Исходный датасет был физически разделён на обучающую, валидационную и тестовую выборки в соотношении 60% / 20% / 20% отдельно для каждого класса. Аугментация данных применялась только к обучающей выборке, что позволяет повысить обобщающую способность модели и избежать искажения оценок качества на валидационных и тестовых данных."
      ],
      "metadata": {
        "id": "g-tdr7-E3VWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Построение сверточной нейронной сети «с нуля» (Conv2D + MaxPooling + Dense)"
      ],
      "metadata": {
        "id": "s20WFzVv3Yu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. СОЗДАНИЕ CALLBACK'ОВ\n",
        "callbacks = [\n",
        "    # Ранняя остановка при переобучении\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=15,  # Количество эпох без улучшения\n",
        "        restore_best_weights=True,\n",
        "        verbose=1,\n",
        "        mode='min'\n",
        "    ),\n",
        "\n",
        "    # Уменьшение learning rate при плато\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,  # Уменьшение LR в 2 раза\n",
        "        patience=7,  # Количество эпох без улучшения\n",
        "        min_lr=1e-6,  # Минимальный learning rate\n",
        "        verbose=1,\n",
        "        mode='min'\n",
        "    )\n",
        "]\n",
        "\n",
        "# 2. СЛОЙ АУГМЕНТАЦИИ\n",
        "data_augmentation = models.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomContrast(0.1),\n",
        "])\n",
        "\n",
        "# 3. СОЗДАНИЕ МОДЕЛИ С АВТОКОДИРОВЩИКОМ\n",
        "def create_autoencoder_classifier_model():\n",
        "    \"\"\"\n",
        "    Создает комбинированную модель:\n",
        "    - Энкодер для извлечения признаков\n",
        "    - Два выхода: декодер (автокодировщик) и классификатор\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = layers.Input(shape=(224, 224, 3))\n",
        "\n",
        "    # Аугментация данных\n",
        "    x = data_augmentation(inputs)\n",
        "\n",
        "    # Нормализация\n",
        "    x = layers.Rescaling(1./255)(x)\n",
        "\n",
        "    # ЭНКОДЕР (общая часть)\n",
        "    # Блок 1\n",
        "    x = layers.Conv2D(\n",
        "        32, (3, 3),\n",
        "        activation='relu',\n",
        "        padding='same',\n",
        "        kernel_regularizer=regularizers.l2(0.001)\n",
        "    )(x)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "\n",
        "    # Блок 2\n",
        "    x = layers.Conv2D(\n",
        "        64, (3, 3),\n",
        "        activation='relu',\n",
        "        padding='same',\n",
        "        kernel_regularizer=regularizers.l2(0.001)\n",
        "    )(x)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    # Блок 3\n",
        "    x = layers.Conv2D(\n",
        "        128, (3, 3),\n",
        "        activation='relu',\n",
        "        padding='same',\n",
        "        kernel_regularizer=regularizers.l2(0.001)\n",
        "    )(x)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Блок 4 (боттлнек - сжатое представление)\n",
        "    encoded = layers.Conv2D(\n",
        "        256, (3, 3),\n",
        "        activation='relu',\n",
        "        padding='same',\n",
        "        kernel_regularizer=regularizers.l2(0.001),\n",
        "        name='bottleneck'\n",
        "    )(x)\n",
        "    encoded = layers.MaxPooling2D((2, 2), padding='same')(encoded)\n",
        "\n",
        "    # ДЕКОДЕР (для автокодировщика)\n",
        "    # Начинаем декодирование от боттлнека\n",
        "    # Блок 1 декодера\n",
        "    d = layers.Conv2D(\n",
        "        256, (3, 3),\n",
        "        activation='relu',\n",
        "        padding='same'\n",
        "    )(encoded)\n",
        "    d = layers.UpSampling2D((2, 2))(d)\n",
        "    d = layers.Dropout(0.3)(d)\n",
        "\n",
        "    # Блок 2 декодера\n",
        "    d = layers.Conv2D(\n",
        "        128, (3, 3),\n",
        "        activation='relu',\n",
        "        padding='same'\n",
        "    )(d)\n",
        "    d = layers.UpSampling2D((2, 2))(d)\n",
        "    d = layers.Dropout(0.2)(d)\n",
        "\n",
        "    # Блок 3 декодера\n",
        "    d = layers.Conv2D(\n",
        "        64, (3, 3),\n",
        "        activation='relu',\n",
        "        padding='same'\n",
        "    )(d)\n",
        "    d = layers.UpSampling2D((2, 2))(d)\n",
        "    d = layers.Dropout(0.1)(d)\n",
        "\n",
        "    # Блок 4 декодера\n",
        "    d = layers.Conv2D(\n",
        "        32, (3, 3),\n",
        "        activation='relu',\n",
        "        padding='same'\n",
        "    )(d)\n",
        "    d = layers.UpSampling2D((2, 2))(d)\n",
        "\n",
        "    # Выход декодера (восстановленное изображение)\n",
        "    decoder_output = layers.Conv2D(\n",
        "        3, (3, 3),\n",
        "        activation='sigmoid',\n",
        "        padding='same',\n",
        "        name='decoder_output'\n",
        "    )(d)\n",
        "\n",
        "    # КЛАССИФИКАТОР\n",
        "    # Используем то же сжатое представление (encoded) для классификации\n",
        "    c = layers.GlobalAveragePooling2D()(encoded)\n",
        "\n",
        "    # Полносвязные слои\n",
        "    c = layers.Dense(\n",
        "        256,\n",
        "        activation='relu',\n",
        "        kernel_regularizer=regularizers.l2(0.001)\n",
        "    )(c)\n",
        "    c = layers.Dropout(0.5)(c)\n",
        "\n",
        "    c = layers.Dense(\n",
        "        128,\n",
        "        activation='relu',\n",
        "        kernel_regularizer=regularizers.l2(0.001)\n",
        "    )(c)\n",
        "    c = layers.Dropout(0.3)(c)\n",
        "\n",
        "    # Выход классификатора\n",
        "    classification_output = layers.Dense(\n",
        "        7,\n",
        "        activation='softmax',\n",
        "        name='classification_output'\n",
        "    )(c)\n",
        "\n",
        "    # Создание модели с двумя выходами\n",
        "    model = models.Model(\n",
        "        inputs=inputs,\n",
        "        outputs=[decoder_output, classification_output]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# 4. СОЗДАНИЕ И КОМПИЛЯЦИЯ МОДЕЛИ\n",
        "print(\"=\"*60)\n",
        "print(\"СОЗДАНИЕ МОДЕЛИ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "model = create_autoencoder_classifier_model()\n",
        "\n",
        "# Компиляция с двумя loss функциями\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss={\n",
        "        'decoder_output': 'mse',  # Mean Squared Error для автокодировщика\n",
        "        'classification_output': 'categorical_crossentropy'  # Cross-entropy для классификации\n",
        "    },\n",
        "    loss_weights={\n",
        "        'decoder_output': 0.3,  # Вес для автокодировщика\n",
        "        'classification_output': 1.0  # Основной вес для классификации\n",
        "    },\n",
        "    metrics={\n",
        "        'classification_output': ['accuracy']\n",
        "    }\n",
        ")\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "# 5. ПОДГОТОВКА ГЕНЕРАТОРО\n",
        "def multi_output_generator(generator):\n",
        "    \"\"\"\n",
        "    Подготовка данных для модели с двумя выходами\n",
        "    \"\"\"\n",
        "    for batch_x, batch_y in generator:\n",
        "        yield batch_x, {\n",
        "            'decoder_output': batch_x,  # Для автокодировщика: вход = выход\n",
        "            'classification_output': batch_y  # Для классификатора: истинные метки\n",
        "        }\n",
        "\n",
        "# 9. ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ\n",
        "def plot_training_results(history):\n",
        "    \"\"\"\n",
        "    Визуализация результатов обучения\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # График 1: Точность классификации\n",
        "    axes[0, 0].plot(history.history['classification_output_accuracy'],\n",
        "                   label='Обучающая', linewidth=2)\n",
        "    axes[0, 0].plot(history.history['val_classification_output_accuracy'],\n",
        "                   label='Валидационная', linewidth=2)\n",
        "    axes[0, 0].set_title('Точность классификации', fontsize=14, fontweight='bold')\n",
        "    axes[0, 0].set_xlabel('Эпоха')\n",
        "    axes[0, 0].set_ylabel('Точность')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # График 2: Потери классификации\n",
        "    axes[0, 1].plot(history.history['classification_output_loss'],\n",
        "                   label='Обучающие', linewidth=2)\n",
        "    axes[0, 1].plot(history.history['val_classification_output_loss'],\n",
        "                   label='Валидационные', linewidth=2)\n",
        "    axes[0, 1].set_title('Потери классификации', fontsize=14, fontweight='bold')\n",
        "    axes[0, 1].set_xlabel('Эпоха')\n",
        "    axes[0, 1].set_ylabel('Потери')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # График 3: Потери автокодировщика\n",
        "    axes[1, 0].plot(history.history['decoder_output_loss'],\n",
        "                   label='Обучающие', linewidth=2)\n",
        "    axes[1, 0].plot(history.history['val_decoder_output_loss'],\n",
        "                   label='Валидационные', linewidth=2)\n",
        "    axes[1, 0].set_title('Потери автокодировщика (MSE)', fontsize=14, fontweight='bold')\n",
        "    axes[1, 0].set_xlabel('Эпоха')\n",
        "    axes[1, 0].set_ylabel('MSE')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # График 4: Общая потеря\n",
        "    axes[1, 1].plot(history.history['loss'],\n",
        "                   label='Общие обучающие', linewidth=2)\n",
        "    axes[1, 1].plot(history.history['val_loss'],\n",
        "                   label='Общие валидационные', linewidth=2)\n",
        "    axes[1, 1].set_title('Общие потери', fontsize=14, fontweight='bold')\n",
        "    axes[1, 1].set_xlabel('Эпоха')\n",
        "    axes[1, 1].set_ylabel('Потери')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.suptitle('РЕЗУЛЬТАТЫ ОБУЧЕНИЯ', fontsize=16, fontweight='bold', y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_training_results(history)\n",
        "\n",
        "# 10. ВИЗУАЛИЗАЦИЯ РАБОТЫ АВТОКОДИРОВЩИКА\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ВИЗУАЛИЗАЦИЯ РАБОТЫ АВТОКОДИРОВЩИКА\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Получаем один батч изображений\n",
        "sample_batch = next(train_generator)\n",
        "sample_images = sample_batch[0][:6]\n",
        "\n",
        "# Получаем выход декодера\n",
        "decoded_images = model.predict(sample_images)[0]  # Первый выход - декодер\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i in range(6):\n",
        "    # Оригинальное изображение\n",
        "    ax = plt.subplot(3, 6, i + 1)\n",
        "    plt.imshow(sample_images[i])\n",
        "    plt.title(\"Оригинал\" if i == 0 else \"\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Восстановленное изображение\n",
        "    ax = plt.subplot(3, 6, i + 7)\n",
        "    plt.imshow(decoded_images[i])\n",
        "    plt.title(\"Восстановлено\" if i == 0 else \"\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Разница\n",
        "    ax = plt.subplot(3, 6, i + 13)\n",
        "    difference = np.abs(sample_images[i] - decoded_images[i])\n",
        "    plt.imshow(difference)\n",
        "    plt.title(\"Разница\" if i == 0 else \"\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.suptitle('Работа автокодировщика: оригинал vs восстановление',\n",
        "             fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 11. ВИЗУАЛИЗАЦИЯ ПРЕДСКАЗАНИЙ\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ВИЗУАЛИЗАЦИЯ ПРЕДСКАЗАНИЙ НА ТЕСТОВЫХ ДАННЫХ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Получаем батч тестовых данных\n",
        "test_images, test_labels = next(test_generator)\n",
        "\n",
        "# Делаем предсказания\n",
        "predictions = classification_model.predict(test_images[:12])\n",
        "\n",
        "# Визуализируем результаты\n",
        "class_names = [\"Auto Rickshaws\", \"Bikes\", \"Cars\", \"Motorcycles\",\n",
        "               \"Planes\", \"Ships\", \"Trains\"]\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i in range(12):\n",
        "    plt.subplot(3, 4, i + 1)\n",
        "    plt.imshow(test_images[i])\n",
        "\n",
        "    true_class = np.argmax(test_labels[i])\n",
        "    pred_class = np.argmax(predictions[i])\n",
        "    confidence = np.max(predictions[i])\n",
        "\n",
        "    true_name = class_names[true_class]\n",
        "    pred_name = class_names[pred_class]\n",
        "\n",
        "    color = 'green' if true_class == pred_class else 'red'\n",
        "\n",
        "    plt.title(f\"True: {true_name[:10]}\\nPred: {pred_name[:10]}\\nConf: {confidence:.2f}\",\n",
        "              color=color, fontsize=9)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.suptitle('Примеры предсказаний на тестовых данных', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 12. АНАЛИЗ РЕЗУЛЬТАТОВ\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"АНАЛИЗ РЕЗУЛЬТАТОВ ОБУЧЕНИЯ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Получаем лучшие результаты\n",
        "best_val_acc = max(history.history['val_classification_output_accuracy'])\n",
        "best_val_loss = min(history.history['val_classification_output_loss'])\n",
        "final_train_acc = history.history['classification_output_accuracy'][-1]\n",
        "final_val_acc = history.history['val_classification_output_accuracy'][-1]\n",
        "\n",
        "print(f\"Лучшая валидационная точность: {best_val_acc:.4f}\")\n",
        "print(f\"Лучшие валидационные потери: {best_val_loss:.4f}\")\n",
        "print(f\"Финальная обучающая точность: {final_train_acc:.4f}\")\n",
        "print(f\"Финальная валидационная точность: {final_val_acc:.4f}\")\n",
        "print(f\"Финальная тестовая точность: {test_results[1]:.4f}\")\n",
        "\n",
        "# Анализ переобучения\n",
        "overfitting_gap = final_train_acc - final_val_acc\n",
        "print(f\"\\nРазница между train и val точностью: {overfitting_gap:.4f}\")\n",
        "\n",
        "if overfitting_gap > 0.15:\n",
        "    print(\"СТАТУС: Сильное переобучение!\")\n",
        "elif overfitting_gap > 0.05:\n",
        "    print(\"СТАТУС: Умеренное переобучение\")\n",
        "else:\n",
        "    print(\"СТАТУС: Хорошая обобщающая способность\")\n",
        "\n",
        "# Анализ эффективности автокодировщика\n",
        "final_autoencoder_loss = history.history['decoder_output_loss'][-1]\n",
        "final_autoencoder_val_loss = history.history['val_decoder_output_loss'][-1]\n",
        "print(f\"\\nПотери автокодировщика (train): {final_autoencoder_loss:.4f}\")\n",
        "print(f\"Потери автокодировщика (val): {final_autoencoder_val_loss:.4f}\")"
      ],
      "metadata": {
        "id": "9RjSlToVAEn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. ОБУЧЕНИЕ МОДЕЛИ\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ОБУЧЕНИЕ МОДЕЛИ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "history = model.fit(\n",
        "    multi_output_generator(train_generator),\n",
        "    steps_per_epoch=max(1, num_train // batch_size),\n",
        "    epochs=100,\n",
        "    validation_data=multi_output_generator(val_generator),\n",
        "    validation_steps=max(1, num_val // batch_size),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 7. СОЗДАНИЕ ОТДЕЛЬНОЙ МОДЕЛИ КЛАССИФИКАТОРА\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"СОЗДАНИЕ ЧИСТОЙ МОДЕЛИ КЛАССИФИКАТОРА\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Создаем модель только для классификации (без декодера)\n",
        "classification_model = Model(\n",
        "    inputs=model.input,\n",
        "    outputs=model.get_layer('classification_output').output\n",
        ")\n",
        "\n",
        "# Компилируем только для классификации\n",
        "classification_model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# classification_model.summary()\n",
        "\n",
        "# 8. ОЦЕНКА НА ТЕСТОВЫХ ДАННЫХ\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ОЦЕНКА НА ТЕСТОВОЙ ВЫБОРКЕ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "test_results = classification_model.evaluate(\n",
        "    test_generator,\n",
        "    steps=max(1, num_test // batch_size),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(f\"\\nТЕСТОВЫЕ МЕТРИКИ:\")\n",
        "print(f\"Loss: {test_results[0]:.4f}\")\n",
        "print(f\"Accuracy: {test_results[1]:.4f}\")\n"
      ],
      "metadata": {
        "id": "jd7BFufnJSOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ\n",
        "def plot_training_results(history):\n",
        "    \"\"\"\n",
        "    Визуализация результатов обучения\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # График 1: Точность классификации\n",
        "    axes[0, 0].plot(history.history['classification_output_accuracy'],\n",
        "                   label='Обучающая', linewidth=2)\n",
        "    axes[0, 0].plot(history.history['val_classification_output_accuracy'],\n",
        "                   label='Валидационная', linewidth=2)\n",
        "    axes[0, 0].set_title('Точность классификации', fontsize=14, fontweight='bold')\n",
        "    axes[0, 0].set_xlabel('Эпоха')\n",
        "    axes[0, 0].set_ylabel('Точность')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # График 2: Потери классификации\n",
        "    axes[0, 1].plot(history.history['classification_output_loss'],\n",
        "                   label='Обучающие', linewidth=2)\n",
        "    axes[0, 1].plot(history.history['val_classification_output_loss'],\n",
        "                   label='Валидационные', linewidth=2)\n",
        "    axes[0, 1].set_title('Потери классификации', fontsize=14, fontweight='bold')\n",
        "    axes[0, 1].set_xlabel('Эпоха')\n",
        "    axes[0, 1].set_ylabel('Потери')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # График 3: Потери автокодировщика\n",
        "    axes[1, 0].plot(history.history['decoder_output_loss'],\n",
        "                   label='Обучающие', linewidth=2)\n",
        "    axes[1, 0].plot(history.history['val_decoder_output_loss'],\n",
        "                   label='Валидационные', linewidth=2)\n",
        "    axes[1, 0].set_title('Потери автокодировщика (MSE)', fontsize=14, fontweight='bold')\n",
        "    axes[1, 0].set_xlabel('Эпоха')\n",
        "    axes[1, 0].set_ylabel('MSE')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # График 4: Общая потеря\n",
        "    axes[1, 1].plot(history.history['loss'],\n",
        "                   label='Общие обучающие', linewidth=2)\n",
        "    axes[1, 1].plot(history.history['val_loss'],\n",
        "                   label='Общие валидационные', linewidth=2)\n",
        "    axes[1, 1].set_title('Общие потери', fontsize=14, fontweight='bold')\n",
        "    axes[1, 1].set_xlabel('Эпоха')\n",
        "    axes[1, 1].set_ylabel('Потери')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.suptitle('РЕЗУЛЬТАТЫ ОБУЧЕНИЯ', fontsize=16, fontweight='bold', y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_training_results(history)"
      ],
      "metadata": {
        "id": "BM46ODGNJeVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. ВИЗУАЛИЗАЦИЯ РАБОТЫ АВТОКОДИРОВЩИКА\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ВИЗУАЛИЗАЦИЯ РАБОТЫ АВТОКОДИРОВЩИКА\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Получаем один батч изображений\n",
        "sample_batch = next(train_generator)\n",
        "sample_images = sample_batch[0][:6]\n",
        "\n",
        "# Получаем выход декодера\n",
        "decoded_images = model.predict(sample_images)[0]  # Первый выход - декодер\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i in range(6):\n",
        "    # Оригинальное изображение\n",
        "    ax = plt.subplot(3, 6, i + 1)\n",
        "    plt.imshow(sample_images[i])\n",
        "    plt.title(\"Оригинал\" if i == 0 else \"\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Восстановленное изображение\n",
        "    ax = plt.subplot(3, 6, i + 7)\n",
        "    plt.imshow(decoded_images[i])\n",
        "    plt.title(\"Восстановлено\" if i == 0 else \"\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Разница\n",
        "    ax = plt.subplot(3, 6, i + 13)\n",
        "    difference = np.abs(sample_images[i] - decoded_images[i])\n",
        "    plt.imshow(difference)\n",
        "    plt.title(\"Разница\" if i == 0 else \"\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.suptitle('Работа автокодировщика: оригинал vs восстановление',\n",
        "             fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7vFuKzEBJuL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. ВИЗУАЛИЗАЦИЯ ПРЕДСКАЗАНИЙ\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ВИЗУАЛИЗАЦИЯ ПРЕДСКАЗАНИЙ НА ТЕСТОВЫХ ДАННЫХ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Получаем батч тестовых данных\n",
        "test_images, test_labels = next(test_generator)\n",
        "\n",
        "# Делаем предсказания\n",
        "predictions = classification_model.predict(test_images[:12])\n",
        "\n",
        "# Визуализируем результаты\n",
        "class_names = [\"Auto Rickshaws\", \"Bikes\", \"Cars\", \"Motorcycles\",\n",
        "               \"Planes\", \"Ships\", \"Trains\"]\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i in range(12):\n",
        "    plt.subplot(3, 4, i + 1)\n",
        "    plt.imshow(test_images[i])\n",
        "\n",
        "    true_class = np.argmax(test_labels[i])\n",
        "    pred_class = np.argmax(predictions[i])\n",
        "    confidence = np.max(predictions[i])\n",
        "\n",
        "    true_name = class_names[true_class]\n",
        "    pred_name = class_names[pred_class]\n",
        "\n",
        "    color = 'green' if true_class == pred_class else 'red'\n",
        "\n",
        "    plt.title(f\"True: {true_name[:10]}\\nPred: {pred_name[:10]}\\nConf: {confidence:.2f}\",\n",
        "              color=color, fontsize=9)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.suptitle('Примеры предсказаний на тестовых данных', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eacCTROmJ036"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. АНАЛИЗ РЕЗУЛЬТАТОВ\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"АНАЛИЗ РЕЗУЛЬТАТОВ ОБУЧЕНИЯ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Получаем лучшие результаты\n",
        "best_val_acc = max(history.history['val_classification_output_accuracy'])\n",
        "best_val_loss = min(history.history['val_classification_output_loss'])\n",
        "final_train_acc = history.history['classification_output_accuracy'][-1]\n",
        "final_val_acc = history.history['val_classification_output_accuracy'][-1]\n",
        "\n",
        "print(f\"Лучшая валидационная точность: {best_val_acc:.4f}\")\n",
        "print(f\"Лучшие валидационные потери: {best_val_loss:.4f}\")\n",
        "print(f\"Финальная обучающая точность: {final_train_acc:.4f}\")\n",
        "print(f\"Финальная валидационная точность: {final_val_acc:.4f}\")\n",
        "print(f\"Финальная тестовая точность: {test_results[1]:.4f}\")\n",
        "\n",
        "# Анализ переобучения\n",
        "overfitting_gap = final_train_acc - final_val_acc\n",
        "print(f\"\\nРазница между train и val точностью: {overfitting_gap:.4f}\")\n",
        "\n",
        "if overfitting_gap > 0.15:\n",
        "    print(\"СТАТУС: Сильное переобучение!\")\n",
        "elif overfitting_gap > 0.05:\n",
        "    print(\"СТАТУС: Умеренное переобучение\")\n",
        "else:\n",
        "    print(\"СТАТУС: Хорошая обобщающая способность\")\n",
        "\n",
        "# Анализ эффективности автокодировщика\n",
        "final_autoencoder_loss = history.history['decoder_output_loss'][-1]\n",
        "final_autoencoder_val_loss = history.history['val_decoder_output_loss'][-1]\n",
        "print(f\"\\nПотери автокодировщика (train): {final_autoencoder_loss:.4f}\")\n",
        "print(f\"Потери автокодировщика (val): {final_autoencoder_val_loss:.4f}\")"
      ],
      "metadata": {
        "id": "zXUWXOQhJ9dh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}