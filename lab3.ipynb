{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##1. Загрузка пакетов - библиотек"
      ],
      "metadata": {
        "id": "irNrFiBZHxDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импорт необходимых библиотек\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import shutil\n",
        "import random\n",
        "from keras import models, layers\n",
        "from keras import regularizers\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Установка seed для воспроизводимости результатов\n",
        "np.random.seed(17)\n",
        "tf.random.set_seed(17)"
      ],
      "metadata": {
        "id": "m9HnSAoNKXqS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Загрузка датасета"
      ],
      "metadata": {
        "id": "B4VoSphR0f2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_root = Path(\"/content/iad-lab3/Vehicles\")\n",
        "\n",
        "# Проверка наличия датасета\n",
        "if dataset_root.exists():\n",
        "    print(\"Датасет уже найден по указанному пути.\")\n",
        "else:\n",
        "    print(\"Датасет не найден. Выполняется загрузка с GitHub...\")\n",
        "    !git clone https://github.com/Daria-Chernykh/iad-lab3.git\n",
        "\n",
        "# Получение списка классов (подкаталогов)\n",
        "class_names = sorted(\n",
        "    [item.name for item in dataset_root.iterdir() if item.is_dir()]\n",
        ")\n",
        "\n",
        "# Фиксация количества классов\n",
        "num_classes = len(class_names)\n",
        "\n",
        "print(\"\\nНайденные классы:\")\n",
        "for idx, class_name in enumerate(class_names):\n",
        "    print(f\"{idx + 1}. {class_name}\")\n",
        "\n",
        "print(f\"\\nКоличество классов k = {num_classes}\")\n",
        "\n",
        "# Допустимые расширения изображений (в нижнем регистре)\n",
        "image_extensions = {\".jpg\", \".jpeg\", \".png\", \".gif\", \".webp\"}\n",
        "\n",
        "# Подсчёт количества изображений в каждой папке класса\n",
        "print(\"\\nКоличество изображений по классам:\")\n",
        "\n",
        "total_images = 0\n",
        "\n",
        "for class_name in class_names:\n",
        "    class_path = dataset_root / class_name\n",
        "\n",
        "    num_images = sum(\n",
        "        1 for f in class_path.iterdir()\n",
        "        if f.is_file() and f.suffix.lower() in image_extensions\n",
        "    )\n",
        "\n",
        "    total_images += num_images\n",
        "    print(f\"{class_name}: {num_images}\")\n",
        "\n",
        "print(f\"\\nОбщее количество изображений в датасете: {total_images}\")"
      ],
      "metadata": {
        "id": "iOSiIIAa2LE9",
        "outputId": "44c5bb2a-1c6f-400f-b3c1-640ccea191a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Датасет уже найден по указанному пути.\n",
            "\n",
            "Найденные классы:\n",
            "1. Auto Rickshaws\n",
            "2. Bikes\n",
            "3. Cars\n",
            "4. Motorcycles\n",
            "5. Planes\n",
            "6. Ships\n",
            "7. Trains\n",
            "\n",
            "Количество классов k = 7\n",
            "\n",
            "Количество изображений по классам:\n",
            "Auto Rickshaws: 800\n",
            "Bikes: 800\n",
            "Cars: 790\n",
            "Motorcycles: 800\n",
            "Planes: 800\n",
            "Ships: 800\n",
            "Trains: 800\n",
            "\n",
            "Общее количество изображений в датасете: 5590\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В лабораторной работе используется датасет изображений транспортных средств (Vehicles). Набор данных включает 7 классов:\n",
        "* Авторикши (Auto Rickshaws),\n",
        "* Велосипеды (Bikes),\n",
        "* Машины (Cars),\n",
        "* Мотоциклы (Motorcycles),\n",
        "* Самолеты (Planes),\n",
        "* Корабли (Ships),\n",
        "* Поезда (Trains).\n",
        "\n",
        "Каждый класс представлен отдельной папкой с изображениями. Общее количество изображений в датасете составляет 5590. Число изображений в классах близко по величине (от 790 до 800 изображений на класс), что позволяет считать датасет практически сбалансированным и пригодным для решения задачи многоклассовой классификации с использованием сверточных нейронных сетей."
      ],
      "metadata": {
        "id": "RLYGz73vqKMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Выбор и фиксация размерности изображений"
      ],
      "metadata": {
        "id": "hpBia6nQutTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Фиксация размерности входных изображений\n",
        "img_height = 128\n",
        "img_width = 128\n",
        "input_shape = (img_height, img_width, 3)\n",
        "\n",
        "# Размер мини-пакета\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "XNlRPlVYu1cJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Формирование обучающей, валидационной и тестовой выборок"
      ],
      "metadata": {
        "id": "rQj-wGD0wmsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####4.1 Физическое разбиение датасета по папкам"
      ],
      "metadata": {
        "id": "5XvMBL3w2rpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_root = Path(\"/content/iad-lab3/Vehicles\")\n",
        "target_root = Path(\"/content/Vehicles_split\")\n",
        "\n",
        "train_ratio = 0.6\n",
        "val_ratio = 0.2\n",
        "test_ratio = 0.2\n",
        "\n",
        "image_extensions = {\".jpg\", \".jpeg\", \".png\", \".gif\", \".webp\"}\n",
        "\n",
        "# Создание структуры каталогов\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    for class_dir in source_root.iterdir():\n",
        "        if class_dir.is_dir():\n",
        "            (target_root / split / class_dir.name).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Разбиение изображений по классам\n",
        "for class_dir in source_root.iterdir():\n",
        "    if not class_dir.is_dir():\n",
        "        continue\n",
        "\n",
        "    images = [\n",
        "        img for img in class_dir.iterdir()\n",
        "        if img.is_file() and img.suffix.lower() in image_extensions\n",
        "    ]\n",
        "\n",
        "    random.shuffle(images)\n",
        "\n",
        "    n_total = len(images)\n",
        "    n_train = int(n_total * train_ratio)\n",
        "    n_val = int(n_total * val_ratio)\n",
        "\n",
        "    train_images = images[:n_train]\n",
        "    val_images = images[n_train:n_train + n_val]\n",
        "    test_images = images[n_train + n_val:]\n",
        "\n",
        "    for img in train_images:\n",
        "        shutil.copy(img, target_root / \"train\" / class_dir.name / img.name)\n",
        "\n",
        "    for img in val_images:\n",
        "        shutil.copy(img, target_root / \"val\" / class_dir.name / img.name)\n",
        "\n",
        "    for img in test_images:\n",
        "        shutil.copy(img, target_root / \"test\" / class_dir.name / img.name)\n",
        "\n",
        "print(\"Разбиение датасета на train / val / test завершено.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMu-ECS12wS6",
        "outputId": "f80d545b-c539-4fc8-9d0e-e381e433fdf4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Разбиение датасета на train / val / test завершено.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####4.2 Создание генераторов изображений"
      ],
      "metadata": {
        "id": "NF2Xf7XZ3BKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Генератор с аугментацией — только для обучающей выборки\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Генераторы без аугментации — для валидации и теста\n",
        "val_test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    target_root / \"train\",\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "val_generator = val_test_datagen.flow_from_directory(\n",
        "    target_root / \"val\",\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    target_root / \"test\",\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFzH1bZ-wxWB",
        "outputId": "a8ad6d22-dd48-4eca-fad2-1b576ffaa874"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5452 images belonging to 7 classes.\n",
            "Found 3292 images belonging to 7 classes.\n",
            "Found 3315 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####4.3 Вывод количества изображений в каждой выборке"
      ],
      "metadata": {
        "id": "fCVokdIs3K0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_train = train_generator.samples\n",
        "num_val = val_generator.samples\n",
        "num_test = test_generator.samples\n",
        "\n",
        "print(\"Количество изображений в выборках:\")\n",
        "print(f\"Обучающая выборка: {num_train}\")\n",
        "print(f\"Валидационная выборка: {num_val}\")\n",
        "print(f\"Тестовая выборка: {num_test}\")\n",
        "print(f\"Общее количество изображений: {num_train + num_val + num_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3VsfvFF3OxT",
        "outputId": "c8515b36-4a26-4d93-dc60-6e00f02d6fce"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество изображений в выборках:\n",
            "Обучающая выборка: 5452\n",
            "Валидационная выборка: 3292\n",
            "Тестовая выборка: 3315\n",
            "Общее количество изображений: 12059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Исходный датасет был физически разделён на обучающую, валидационную и тестовую выборки в соотношении 60% / 20% / 20% отдельно для каждого класса. Аугментация данных применялась только к обучающей выборке, что позволяет повысить обобщающую способность модели и избежать искажения оценок качества на валидационных и тестовых данных."
      ],
      "metadata": {
        "id": "g-tdr7-E3VWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Построение сверточной нейронной сети «с нуля» (Conv2D + MaxPooling + Dense)"
      ],
      "metadata": {
        "id": "s20WFzVv3Yu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. СОЗДАНИЕ CALLBACK'ОВ\n",
        "callbacks = [\n",
        "    # Ранняя остановка при переобучении\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=15,  # Количество эпох без улучшения\n",
        "        restore_best_weights=True,\n",
        "        verbose=1,\n",
        "        mode='min'\n",
        "    ),\n",
        "\n",
        "    # Уменьшение learning rate при плато\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,  # Уменьшение LR в 2 раза\n",
        "        patience=7,  # Количество эпох без улучшения\n",
        "        min_lr=1e-6,  # Минимальный learning rate\n",
        "        verbose=1,\n",
        "        mode='min'\n",
        "    )\n",
        "]\n",
        "\n",
        "# 2. СЛОЙ АУГМЕНТАЦИИ\n",
        "data_augmentation = models.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "])\n",
        "\n",
        "# 3. СОЗДАНИЕ МОДЕЛИ С АВТОКОДИРОВЩИКОМ\n",
        "def create_autoencoder_classifier_model():\n",
        "    \"\"\"\n",
        "    Создает комбинированную модель:\n",
        "    - Энкодер для извлечения признаков\n",
        "    - Два выхода: декодер (автокодировщик) и классификатор\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = layers.Input(shape=(128, 128, 3))\n",
        "\n",
        "    # Аугментация данных\n",
        "    x = data_augmentation(inputs)\n",
        "\n",
        "    # Нормализация\n",
        "    x = layers.Rescaling(1./255)(x)\n",
        "\n",
        "    # ЭНКОДЕР (общая часть)\n",
        "    # Блок 1\n",
        "    x = layers.Conv2D(\n",
        "        32, (3, 3),\n",
        "        activation='relu',\n",
        "        padding='same',\n",
        "        kernel_regularizer=regularizers.l2(0.001)\n",
        "    )(x)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "\n",
        "    # Блок 2\n",
        "    x = layers.Conv2D(\n",
        "        64, (3, 3),\n",
        "        activation='relu',\n",
        "        padding='same',\n",
        "        kernel_regularizer=regularizers.l2(0.001)\n",
        "    )(x)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    # Блок 3\n",
        "    x = layers.Conv2D(\n",
        "        128, (3, 3),\n",
        "        activation='relu',\n",
        "        padding='same',\n",
        "        kernel_regularizer=regularizers.l2(0.001)\n",
        "    )(x)\n",
        "    encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    # ДЕКОДЕР (для автокодировщика)\n",
        "    # Начинаем декодирование от боттлнека\n",
        "    # Блок 1 декодера\n",
        "    d = layers.Conv2D(\n",
        "        128, (3, 3),\n",
        "        activation='relu',\n",
        "        padding='same'\n",
        "    )(d)\n",
        "    d = layers.UpSampling2D((2, 2))(d)\n",
        "    d = layers.Dropout(0.2)(d)\n",
        "\n",
        "    # Блок 2 декодера\n",
        "    d = layers.Conv2D(\n",
        "        64, (3, 3),\n",
        "        activation='relu',\n",
        "        padding='same'\n",
        "    )(d)\n",
        "    d = layers.UpSampling2D((2, 2))(d)\n",
        "    d = layers.Dropout(0.1)(d)\n",
        "\n",
        "    # Блок 3 декодера\n",
        "    d = layers.Conv2D(\n",
        "        32, (3, 3),\n",
        "        activation='relu',\n",
        "        padding='same'\n",
        "    )(d)\n",
        "    d = layers.UpSampling2D((2, 2))(d)\n",
        "\n",
        "    # Выход декодера (восстановленное изображение)\n",
        "    decoder_output = layers.Conv2D(\n",
        "        3, (3, 3),\n",
        "        activation='sigmoid',\n",
        "        padding='same',\n",
        "        name='decoder_output'\n",
        "    )(d)\n",
        "\n",
        "    # КЛАССИФИКАТОР\n",
        "    # Используем то же сжатое представление (encoded) для классификации\n",
        "    c = layers.GlobalAveragePooling2D()(encoded)\n",
        "\n",
        "    # Полносвязные слои\n",
        "    c = layers.Dense(\n",
        "        128,\n",
        "        activation='relu',\n",
        "        kernel_regularizer=regularizers.l2(0.001)\n",
        "    )(c)\n",
        "    c = layers.Dropout(0.5)(c)\n",
        "\n",
        "    c = layers.Dense(\n",
        "        64,\n",
        "        activation='relu',\n",
        "        kernel_regularizer=regularizers.l2(0.001)\n",
        "    )(c)\n",
        "    c = layers.Dropout(0.3)(c)\n",
        "\n",
        "    # Выход классификатора\n",
        "    classification_output = layers.Dense(\n",
        "        7,\n",
        "        activation='softmax',\n",
        "        name='classification_output'\n",
        "    )(c)\n",
        "\n",
        "    # Создание модели с двумя выходами\n",
        "    model = models.Model(\n",
        "        inputs=inputs,\n",
        "        outputs=[decoder_output, classification_output]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# 4. СОЗДАНИЕ И КОМПИЛЯЦИЯ МОДЕЛИ\n",
        "print(\"=\"*60)\n",
        "print(\"СОЗДАНИЕ МОДЕЛИ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "model = create_autoencoder_classifier_model()\n",
        "\n",
        "# Компиляция с двумя loss функциями\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss={\n",
        "        'decoder_output': 'mse',  # Mean Squared Error для автокодировщика\n",
        "        'classification_output': 'categorical_crossentropy'  # Cross-entropy для классификации\n",
        "    },\n",
        "    loss_weights={\n",
        "        'decoder_output': 0.3,  # Вес для автокодировщика\n",
        "        'classification_output': 1.0  # Основной вес для классификации\n",
        "    },\n",
        "    metrics={\n",
        "        'classification_output': ['accuracy']\n",
        "    }\n",
        ")\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "# 5. ПОДГОТОВКА ГЕНЕРАТОРО\n",
        "def multi_output_generator(generator):\n",
        "    \"\"\"\n",
        "    Подготовка данных для модели с двумя выходами\n",
        "    \"\"\"\n",
        "    for batch_x, batch_y in generator:\n",
        "        yield batch_x, {\n",
        "            'decoder_output': batch_x,  # Для автокодировщика: вход = выход\n",
        "            'classification_output': batch_y  # Для классификатора: истинные метки\n",
        "        }\n"
      ],
      "metadata": {
        "id": "9RjSlToVAEn9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0119c194-74f8-4270-deb4-56fadf165a12"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "СОЗДАНИЕ МОДЕЛИ\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. ОБУЧЕНИЕ МОДЕЛИ\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ОБУЧЕНИЕ МОДЕЛИ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "history = model.fit(\n",
        "    multi_output_generator(train_generator),\n",
        "    steps_per_epoch=max(1, num_train // batch_size),\n",
        "    epochs=100,\n",
        "    validation_data=multi_output_generator(val_generator),\n",
        "    validation_steps=max(1, num_val // batch_size),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 7. СОЗДАНИЕ ОТДЕЛЬНОЙ МОДЕЛИ КЛАССИФИКАТОРА\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"СОЗДАНИЕ ЧИСТОЙ МОДЕЛИ КЛАССИФИКАТОРА\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Создаем модель только для классификации (без декодера)\n",
        "classification_model = Model(\n",
        "    inputs=model.input,\n",
        "    outputs=model.get_layer('classification_output').output\n",
        ")\n",
        "\n",
        "# Компилируем только для классификации\n",
        "classification_model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# classification_model.summary()\n",
        "\n",
        "# 8. ОЦЕНКА НА ТЕСТОВЫХ ДАННЫХ\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ОЦЕНКА НА ТЕСТОВОЙ ВЫБОРКЕ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "test_results = classification_model.evaluate(\n",
        "    test_generator,\n",
        "    steps=max(1, num_test // batch_size),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(f\"\\nТЕСТОВЫЕ МЕТРИКИ:\")\n",
        "print(f\"Loss: {test_results[0]:.4f}\")\n",
        "print(f\"Accuracy: {test_results[1]:.4f}\")\n"
      ],
      "metadata": {
        "id": "jd7BFufnJSOs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "95234b5c-ec3d-4bfb-9ab8-11c63f44f827"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ОБУЧЕНИЕ МОДЕЛИ\n",
            "============================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m 10/170\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31:27\u001b[0m 12s/step - classification_output_accuracy: 0.1344 - classification_output_loss: 1.9461 - decoder_output_loss: 0.0882 - loss: 2.6433"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m130/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m7:54\u001b[0m 12s/step - classification_output_accuracy: 0.1322 - classification_output_loss: 1.9466 - decoder_output_loss: 0.0908 - loss: 2.2955"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4197523387.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmulti_output_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_train\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ\n",
        "def plot_training_results(history):\n",
        "    \"\"\"\n",
        "    Визуализация результатов обучения\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # График 1: Точность классификации\n",
        "    axes[0, 0].plot(history.history['classification_output_accuracy'],\n",
        "                   label='Обучающая', linewidth=2)\n",
        "    axes[0, 0].plot(history.history['val_classification_output_accuracy'],\n",
        "                   label='Валидационная', linewidth=2)\n",
        "    axes[0, 0].set_title('Точность классификации', fontsize=14, fontweight='bold')\n",
        "    axes[0, 0].set_xlabel('Эпоха')\n",
        "    axes[0, 0].set_ylabel('Точность')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # График 2: Потери классификации\n",
        "    axes[0, 1].plot(history.history['classification_output_loss'],\n",
        "                   label='Обучающие', linewidth=2)\n",
        "    axes[0, 1].plot(history.history['val_classification_output_loss'],\n",
        "                   label='Валидационные', linewidth=2)\n",
        "    axes[0, 1].set_title('Потери классификации', fontsize=14, fontweight='bold')\n",
        "    axes[0, 1].set_xlabel('Эпоха')\n",
        "    axes[0, 1].set_ylabel('Потери')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # График 3: Потери автокодировщика\n",
        "    axes[1, 0].plot(history.history['decoder_output_loss'],\n",
        "                   label='Обучающие', linewidth=2)\n",
        "    axes[1, 0].plot(history.history['val_decoder_output_loss'],\n",
        "                   label='Валидационные', linewidth=2)\n",
        "    axes[1, 0].set_title('Потери автокодировщика (MSE)', fontsize=14, fontweight='bold')\n",
        "    axes[1, 0].set_xlabel('Эпоха')\n",
        "    axes[1, 0].set_ylabel('MSE')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # График 4: Общая потеря\n",
        "    axes[1, 1].plot(history.history['loss'],\n",
        "                   label='Общие обучающие', linewidth=2)\n",
        "    axes[1, 1].plot(history.history['val_loss'],\n",
        "                   label='Общие валидационные', linewidth=2)\n",
        "    axes[1, 1].set_title('Общие потери', fontsize=14, fontweight='bold')\n",
        "    axes[1, 1].set_xlabel('Эпоха')\n",
        "    axes[1, 1].set_ylabel('Потери')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.suptitle('РЕЗУЛЬТАТЫ ОБУЧЕНИЯ', fontsize=16, fontweight='bold', y=1.02)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_training_results(history)"
      ],
      "metadata": {
        "id": "BM46ODGNJeVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. ВИЗУАЛИЗАЦИЯ РАБОТЫ АВТОКОДИРОВЩИКА\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ВИЗУАЛИЗАЦИЯ РАБОТЫ АВТОКОДИРОВЩИКА\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Получаем один батч изображений\n",
        "sample_batch = next(train_generator)\n",
        "sample_images = sample_batch[0][:6]\n",
        "\n",
        "# Получаем выход декодера\n",
        "decoded_images = model.predict(sample_images)[0]  # Первый выход - декодер\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i in range(6):\n",
        "    # Оригинальное изображение\n",
        "    ax = plt.subplot(3, 6, i + 1)\n",
        "    plt.imshow(sample_images[i])\n",
        "    plt.title(\"Оригинал\" if i == 0 else \"\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Восстановленное изображение\n",
        "    ax = plt.subplot(3, 6, i + 7)\n",
        "    plt.imshow(decoded_images[i])\n",
        "    plt.title(\"Восстановлено\" if i == 0 else \"\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Разница\n",
        "    ax = plt.subplot(3, 6, i + 13)\n",
        "    difference = np.abs(sample_images[i] - decoded_images[i])\n",
        "    plt.imshow(difference)\n",
        "    plt.title(\"Разница\" if i == 0 else \"\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.suptitle('Работа автокодировщика: оригинал vs восстановление',\n",
        "             fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7vFuKzEBJuL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. ВИЗУАЛИЗАЦИЯ ПРЕДСКАЗАНИЙ\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ВИЗУАЛИЗАЦИЯ ПРЕДСКАЗАНИЙ НА ТЕСТОВЫХ ДАННЫХ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Получаем батч тестовых данных\n",
        "test_images, test_labels = next(test_generator)\n",
        "\n",
        "# Делаем предсказания\n",
        "predictions = classification_model.predict(test_images[:12])\n",
        "\n",
        "# Визуализируем результаты\n",
        "class_names = [\"Auto Rickshaws\", \"Bikes\", \"Cars\", \"Motorcycles\",\n",
        "               \"Planes\", \"Ships\", \"Trains\"]\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i in range(12):\n",
        "    plt.subplot(3, 4, i + 1)\n",
        "    plt.imshow(test_images[i])\n",
        "\n",
        "    true_class = np.argmax(test_labels[i])\n",
        "    pred_class = np.argmax(predictions[i])\n",
        "    confidence = np.max(predictions[i])\n",
        "\n",
        "    true_name = class_names[true_class]\n",
        "    pred_name = class_names[pred_class]\n",
        "\n",
        "    color = 'green' if true_class == pred_class else 'red'\n",
        "\n",
        "    plt.title(f\"True: {true_name[:10]}\\nPred: {pred_name[:10]}\\nConf: {confidence:.2f}\",\n",
        "              color=color, fontsize=9)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.suptitle('Примеры предсказаний на тестовых данных', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eacCTROmJ036"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. АНАЛИЗ РЕЗУЛЬТАТОВ\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"АНАЛИЗ РЕЗУЛЬТАТОВ ОБУЧЕНИЯ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Получаем лучшие результаты\n",
        "best_val_acc = max(history.history['val_classification_output_accuracy'])\n",
        "best_val_loss = min(history.history['val_classification_output_loss'])\n",
        "final_train_acc = history.history['classification_output_accuracy'][-1]\n",
        "final_val_acc = history.history['val_classification_output_accuracy'][-1]\n",
        "\n",
        "print(f\"Лучшая валидационная точность: {best_val_acc:.4f}\")\n",
        "print(f\"Лучшие валидационные потери: {best_val_loss:.4f}\")\n",
        "print(f\"Финальная обучающая точность: {final_train_acc:.4f}\")\n",
        "print(f\"Финальная валидационная точность: {final_val_acc:.4f}\")\n",
        "print(f\"Финальная тестовая точность: {test_results[1]:.4f}\")\n",
        "\n",
        "# Анализ переобучения\n",
        "overfitting_gap = final_train_acc - final_val_acc\n",
        "print(f\"\\nРазница между train и val точностью: {overfitting_gap:.4f}\")\n",
        "\n",
        "if overfitting_gap > 0.15:\n",
        "    print(\"СТАТУС: Сильное переобучение!\")\n",
        "elif overfitting_gap > 0.05:\n",
        "    print(\"СТАТУС: Умеренное переобучение\")\n",
        "else:\n",
        "    print(\"СТАТУС: Хорошая обобщающая способность\")\n",
        "\n",
        "# Анализ эффективности автокодировщика\n",
        "final_autoencoder_loss = history.history['decoder_output_loss'][-1]\n",
        "final_autoencoder_val_loss = history.history['val_decoder_output_loss'][-1]\n",
        "print(f\"\\nПотери автокодировщика (train): {final_autoencoder_loss:.4f}\")\n",
        "print(f\"Потери автокодировщика (val): {final_autoencoder_val_loss:.4f}\")"
      ],
      "metadata": {
        "id": "zXUWXOQhJ9dh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}